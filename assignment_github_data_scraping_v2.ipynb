{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installed necessary packages\n",
        "!pip install ratelimit\n",
        "!pip install openai\n",
        "\n",
        "import requests\n",
        "import csv\n",
        "import pandas as pd\n",
        "from ratelimit import limits, sleep_and_retry\n",
        "import openai\n",
        "\n",
        "# config for rate limiting\n",
        "CALLS_ALLOWED = 2  # Number of API calls allowed\n",
        "RATE_LIMIT_PERIOD = 60  # Time period in seconds\n",
        "\n",
        "@sleep_and_retry\n",
        "@limits(calls=CALLS_ALLOWED, period=RATE_LIMIT_PERIOD)\n",
        "def enforce_rate_limit():\n",
        "    ''' Ensures compliance with API rate limits '''\n",
        "    return\n",
        "\n",
        "def get_popular_python_repositories():\n",
        "    # Retrieve most popular Python repositories from GitHub API- used similar filters as in bugsplainers repo\n",
        "    url = \"https://api.github.com/search/repositories?q=yield+language:python+archived:false&sort=stars&order=desc&per_page=10000000\"\n",
        "\n",
        "    payload = {}\n",
        "    headers = {\n",
        "        'Accept': 'application/vnd.github+json',\n",
        "        'Authorization': 'Bearer  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',  # Replace with your GitHub token\n",
        "        'X-GitHub-Api-Version': '2022-11-28'\n",
        "    }\n",
        "\n",
        "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        return data[\"items\"]\n",
        "    else:\n",
        "        print(\"Error:\", response.status_code)\n",
        "        return []\n",
        "\n",
        "# get commits list for each repo\n",
        "def get_repository_commits(repo_name, owner):\n",
        "    # Fetch commits of a repository from GitHub API\n",
        "    commits_url = f\"https://api.github.com/repos/{owner}/{repo_name}/commits\"\n",
        "\n",
        "    payload = {}\n",
        "    headers = {\n",
        "        'User-Agent': 'request',\n",
        "        'Accept': 'application/vnd.github+json',\n",
        "        'Authorization': 'Bearer  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',  # Replace with your GitHub token\n",
        "        'X-GitHub-Api-Version': '2022-11-28'\n",
        "    }\n",
        "\n",
        "    response=requests.request(\"GET\", commits_url, headers=headers, data=payload)\n",
        "    if response.status_code == 200:\n",
        "        commits_data = response.json()\n",
        "        return commits_data\n",
        "    else:\n",
        "        print(\"Error:\", response.status_code)\n",
        "        return []\n",
        "\n",
        "# filter function to filter based on keyword list\n",
        "# have also used lambda function in this as requested\n",
        "\n",
        "def filter_commits_by_keywords(commits, keywords):\n",
        "    # Filter commits by specified keywords\n",
        "    contains_keywords = lambda commit: any(keyword in commit['commit']['message'].lower() for keyword in keywords) and 'yield' in commit['commit']['message'].lower()\n",
        "    filtered_commits = filter(contains_keywords, commits)\n",
        "    return list(filtered_commits)\n",
        "\n",
        "def process_commits_and_generate_questions(rows):\n",
        "    # Process commits and generate questions using OpenAI api\n",
        "    for row in rows:\n",
        "        commit_message = row['Commit Message']\n",
        "\n",
        "        enforce_rate_limit()  # Enforce API rate limiting\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": f\"Could you determine if the commit involves performance or memory optimization? -{commit_message}\"}\n",
        "            ]\n",
        "        )\n",
        "        row['GPT3 Response'] = completion.choices[0].message['content']\n",
        "\n",
        "        # Interpret the response as Yes, No, or Maybe\n",
        "        #as mentioned further tried to do definitive filtering based on chatgpt response\n",
        "        response_lower = row['GPT3 Response'].lower()\n",
        "        if 'yes' in response_lower:\n",
        "            row['Interpreted Response'] = 'Yes'\n",
        "        elif 'no' in response_lower:\n",
        "            row['Interpreted Response'] = 'No'\n",
        "        elif 'maybe' in response_lower:\n",
        "            row['Interpreted Response'] = 'Maybe'\n",
        "        else:\n",
        "            row['Interpreted Response'] = 'Uncertain'\n",
        "\n",
        "    return rows\n",
        "\n",
        "def main():\n",
        "\n",
        "    # Obtain most popular repositories and set up OpenAI API\n",
        "    repositories = get_popular_python_repositories()\n",
        "    openai.api_key = \"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\"  # Replace with your OpenAI API key\n",
        "    #list of keywords - added yield\n",
        "    keywords = ['perf', 'speed', 'accelerate', 'fast', 'slow', 'latency', 'unnecessary', 'contention', 'optimize', 'efficient', 'resource', 'memory', 'improve' , 'bandwidth' , 'network', 'overhead', 'crash', 'throughput', 'scale']\n",
        "\n",
        "    all_rows = []\n",
        "\n",
        "    for repo in repositories:\n",
        "        repo_name = repo['name']\n",
        "        owner = repo['owner']['login']\n",
        "        commits = get_repository_commits(repo_name, owner)\n",
        "\n",
        "        # Filter commits based on length and keywords- added both filters\n",
        "        filtered_commit_length = [commit for commit in commits if len(commit['commit']['message']) < 100000000000]\n",
        "        filtered_commits = filter_commits_by_keywords(filtered_commit_length, keywords)\n",
        "\n",
        "        if filtered_commits:\n",
        "            for commit in filtered_commits:\n",
        "                row = {\n",
        "                    'Repository': f\"{owner}/{repo_name}\",\n",
        "                    'Commit Message': commit['commit']['message'],\n",
        "                    'Commit URL': commit['html_url'],\n",
        "                    'GPT3 Response': '',\n",
        "                    'Interpreted Response':''\n",
        "                }\n",
        "                all_rows.append(row)\n",
        "\n",
        "    all_rows_with_responses = process_commits_and_generate_questions(all_rows)\n",
        "\n",
        "    # Write data to CSV- all output is stored in csv\n",
        "    with open('output.csv', 'w', newline='') as csvfile:\n",
        "        fieldnames = ['Repository', 'Commit Message', 'Commit URL', 'GPT3 Response', 'Interpreted Response']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(all_rows_with_responses)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUGpWjrF_QND",
        "outputId": "3adb021d-b032-4211-e05f-3645bdac9244"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ratelimit in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}